{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db46a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import numpy as np\n",
    "import itertools\n",
    "nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a4fc68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Meet', 'VERB')\n",
      "('with', 'ADP')\n",
      "('HR', 'PROPN')\n",
      "('at', 'ADP')\n",
      "('12:30pm', 'NOUN')\n"
     ]
    }
   ],
   "source": [
    "feature = [\"Meet with HR at 12:30pm\"]\n",
    "labels = [\"T\", \"T\", \"T\", \"T\", \"O\", \"O\"]\n",
    "\n",
    "feature_pos = []\n",
    "tokens = nlp(feature[0])\n",
    "for token in tokens:\n",
    "    item = (token.text, token.pos_)\n",
    "    feature_pos.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5c092e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('T', 'T', 'T')\n",
      "('T', 'T', 'O')\n",
      "('T', 'O', 'T')\n",
      "('T', 'O', 'O')\n",
      "('O', 'T', 'T')\n",
      "('O', 'T', 'O')\n",
      "('O', 'O', 'T')\n",
      "('O', 'O', 'O')\n"
     ]
    }
   ],
   "source": [
    "def get_labels(values, n):\n",
    "    sequences = list(itertools.product(values, repeat=n))\n",
    "    return sequences\n",
    "\n",
    "values = [\"T\", \"O\"]\n",
    "n = 3\n",
    "sequences = get_labels(values, n)\n",
    "for seq in sequences:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4493a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Submit', 'the', 'quarterly', 'report', 'by', '6:30am']\n",
      "Tags: ['VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN']\n",
      "Probability of the sequence being correct: [0.0625]\n",
      "Loss to minimize: [1.6028191]\n"
     ]
    }
   ],
   "source": [
    "def f1(tags, labels):\n",
    "    if len(tags) != len(labels):\n",
    "        raise ValueError(\"Tags and labels must have the same length\")\n",
    "    \n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == \"ADJ\" and i > 0:\n",
    "            if labels[i] == \"T\" and (tags[i - 1] == \"DET\" or tags[i - 1] == \"VERB\") and labels[i - 1] == \"T\":\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def f2(tags, labels):\n",
    "    if len(tags) != len(labels):\n",
    "        raise ValueError(\"Tags and labels must have the same length\")\n",
    "    \n",
    "    for i, tag in (enumerate(tags)):\n",
    "        if tag == \"NOUN\" and i > 0:\n",
    "            if labels[i] == \"T\" and tags[i - 1] == \"ADJ\" and labels[i - 1] == \"T\":\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def f3(tags, labels):\n",
    "    if len(tags) != len(labels):\n",
    "        raise ValueError(\"Tags and labels must have the same length\")\n",
    "    \n",
    "    for i, tag in (enumerate(tags)):\n",
    "        if tag == \"VERB\" and  i < len(tags) - 1:\n",
    "            if labels[i] == \"T\" and (tags[i+1] == \"NOUN\" or tags[i+1] == \"ADJ\"):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "sequences = set(get_labels(labels, len(labels)))\n",
    "tags = [item[1] for item in feature_pos]\n",
    "features = [item[0] for item in feature_pos]\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Tags: {tags}\")\n",
    "weight1 = np.random.rand(1)\n",
    "weight2 = np.random.rand(1)\n",
    "weight3 = np.random.rand(1)\n",
    "\n",
    "total = 0\n",
    "for seq in sequences:\n",
    "    output1 = f1(tags, seq) * weight1\n",
    "    output2 = f2(tags, seq) * weight2\n",
    "    output3 = f3(tags, seq) * weight3\n",
    "    \n",
    "    weighted_sum = output1 + output2 + output3\n",
    "    total += weighted_sum\n",
    "\n",
    "true1 = f1(tags, labels) * weight1\n",
    "true2 = f2(tags, labels) * weight2\n",
    "true3 = f3(tags, labels) * weight3\n",
    "true_weighted_sum = true1 + true2 + true3\n",
    "probability = true_weighted_sum / total\n",
    "loss = np.log(total) - true_weighted_sum\n",
    "print(f\"Probability of the sequence being correct: {probability}\")\n",
    "print(f\"Loss to minimize: {float(loss)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5155d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [array([0.38705005]), array([0.47229748]), array([0.36514545])]\n",
      "Updated weights: [array([0.53767342]), array([0.6560778]), array([0.36514545])]\n",
      "Loss after gradient update: 0.6452252379776657\n",
      "Probability of the sequence being correct after update: [0.02746303]\n"
     ]
    }
   ],
   "source": [
    "def loss(true_probability):\n",
    "    return -np.log(true_probability)\n",
    "\n",
    "def z(true_score, sequences, tags, weights):\n",
    "    total = 0\n",
    "    for seq in sequences:\n",
    "        output1 = np.exp(f1(tags, seq) * weights[0])\n",
    "        output2 = np.exp(f2(tags, seq) * weights[1])\n",
    "        output3 = np.exp(f3(tags, seq) * weights[2])\n",
    "        \n",
    "        weighted_sum = output1 + output2 + output3\n",
    "        total += weighted_sum\n",
    "\n",
    "    return np.exp(true_score) / total\n",
    "\n",
    "# ∑​P(y'∣x) * f(x,y') - f(x, y_true) \n",
    "def gradient(true_scores, tags, sequences, weights, learning_rate=0.01):\n",
    "    z_score = z(np.sum(true_scores), sequences, tags, weights) \n",
    "    for seq in sequences:\n",
    "        output1 = f1(tags, seq) * weights[0]\n",
    "        gradient1 = (z_score * output1) - true_scores[0]\n",
    "        weights[0] -= learning_rate * gradient1\n",
    "\n",
    "        output2 = f2(tags, seq) * weights[1]\n",
    "        gradient2 = (z_score * output2) - true_scores[1]\n",
    "        weights[1] -= learning_rate * gradient2\n",
    "\n",
    "        output3 = f3(tags, seq) * weights[2]\n",
    "        gradient3 = (z_score * output3) - true_scores[2]\n",
    "        weights[2] -= learning_rate * gradient3\n",
    "\n",
    "    return weights\n",
    "\n",
    "true_scores = [true1, true2, true3]\n",
    "weights = [weight1, weight2, weight3]\n",
    "print(f\"Initial weights: {weights}\")\n",
    "\n",
    "new_weights = gradient(true_scores, tags, sequences, weights)\n",
    "print(f\"Updated weights: {new_weights}\")\n",
    "print(f\"Loss after gradient update: {loss(np.sum(true_scores))}\")\n",
    "\n",
    "total = 0\n",
    "for seq in sequences:\n",
    "    output1 = f1(tags, seq) * new_weights[0]\n",
    "    output2 = f2(tags, seq) * new_weights[1]\n",
    "    output3 = f3(tags, seq) * new_weights[2]\n",
    "    \n",
    "    weighted_sum = output1 + output2 + output3\n",
    "    total += weighted_sum\n",
    "\n",
    "probability = np.sum(true_scores) / total\n",
    "print(f\"Probability of the sequence being correct after update: {probability}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
